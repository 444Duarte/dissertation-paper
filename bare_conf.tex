%% bare_conf.tex
%% V1.4a
%% 2014/09/17
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8a or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_conf_compsoc.tex,
%%                    bare_jrnl_compsoc.tex, bare_jrnl_transmag.tex
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices and paper sizes can       ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
   \graphicspath{{../pdf/}{../jpeg/}{figures/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
   \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
   \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
   \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )

\usepackage[utf8]{inputenc}
\usepackage{multirow}
\usepackage{listings}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Dynamic Allocation of Serverless Functions\\ in IoT Environments}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{
\IEEEauthorblockN{Duarte Pinto}
\IEEEauthorblockA{
DEI - Faculty of Engineering,\\ University of Porto\\ Porto, Portugal}
\and
\IEEEauthorblockN{João Pedro Dias}
\IEEEauthorblockA{INESC TEC and \\
DEI - Faculty of Engineering,\\ University of Porto\\ Porto, Portugal}
\and
\IEEEauthorblockN{Hugo Sereno Ferreira}
\IEEEauthorblockA{INESC TEC and \\
DEI - Faculty of Engineering,\\ University of Porto\\ Porto, Portugal}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
The IoT area has grown significantly in the last few years and is expected to
reach a gigantic amount of 50 billion devices by 2020\nocite{kn:Cisco01}. Parallel
to IoT, serverless architectures, specifically highlighting \textit{FaaS}, are
also an increasing trend in the field of software engineering. Combining IoT with
a serverless architectural design can be effective when trying to make use of the
local processing power that exist in a local network of IoT devices and creating a
fog layer that leverages compotational capabilities that are closer to the
end-user. The proposed solution, which is placed between the device and the
serverless function, when a device requests for the execution of a serverless
function, will decide based on previous metrics of execution if the serverless
function should be executed locally, in the fog layer of a local network of IoT
devices, or if it should be executed remotely, in one of the many cloud servers.

%The solution makes this decision with the aim of improving response times, by
%taking advantage of the joint processing power of the local network of IoT devices
%when it is more beneficial and suitable to do so.
\end{abstract}

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
Continuing the current trend, mobile data usage is expected to keep increasing
exponentially, part of it thanks to mobile video streaming and
IoT. The estimation is that the number of data that was generated
by mobile devices during the year of 2017 exceeded the $\displaystyle 6 * 10^9$ Gb
per month. Together with the traffic generated by laptops and peer-to-peer
communications, overall traffic demand might reach $\displaystyle 11 * 10^9$ Gb per
month\cite{kn:Dehos2014} \cite{kn:Baresi2017}. To compute such a big amount of
data, cloud computing would appear to be the obvious solution but there are cases
where the latency that comes with transmitting data back and forth might be
undesired. In certain situations it is also not feasible to expect a constant and
reliable internet connection to an always on server, either because it might not
be economically wise or because it might not be infrastructurally possible. In
order to solve the need for low latency, as well as to improve fault tolerance, by
not relying on an always on centralized server, serverless architectures and fog
computing aim to reduce the dependency on the cloud by making more use of the
local resources of a device and improving communication between local devices,
only leaving the data intensive tasks to the cloud\cite{kn:Baresi2017}. With the
increasing trend in serverless solutions, such as AWS Lambda, it is opportunistic
to implement this concepts in IoT.

Although IoT has been around for a few years already, the same cannot be said
about services that provide cloud solutions and cloud infrastructure for rent. 
Likewise, when Serverless and Fog Computing solutions first appeared their
usefulness and benefits for the IoT ecosystem was obvious and developers began to
mix them together in order to get the most out of these new trend.

Despite its success and the promising future for the mix of this concepts, the
area is still fairly new and few solutions can take advantage of the processing
power in the cloud and in the local network of IoT devices in an efficient way
without compromising speed. It is already possible to have a network of IoT
devices working together to execute a series of serverless functions, but not all
serverless functions are suitable to run on low-end devices. To choose where each
serverless functions should be executed (locally or in the cloud) is a manual task
and the end result is that developers choose to have all serverless functions
running in the cloud as it is easier to manage and less risky. Nonetheless, there
is a lot of potiential processing power dormant in each local network that could
be used to improve response times, improve fault-tolerance,  and to slash costs of
hosting cloud processing infrastructure. 

\section{Background}

\subsection{Internet of Things}\label{sec:dialecto}
The \textit{Internet of Things} is a term given to the network of ever increasing
number of mundane objects with embedded systems, that allows them to interact with
each other or with someone remotely. This network creates a more smart and self-regulated
environment that depends less on the input of a physical entity and more on the
input of other \textit{things}, thus removes unnecessary steps and frees the user
of dealing with mundane tasks.

\subsection{Serverless}
Defining the term serverless can be difficult, as the term is both misleading and
its definition overlaps other concepts, such as Platform-as-a-Service (PaaS) and
Software-as-a-Service(SaaS). Serverless stands in between this two concepts, where
the developer loses some control over the cloud infrastructure but maintains
control over the application code \cite{kn:Baldini}.

"The term ‘Serverless’ is confusing since with such applications there are both
server hardware and server processes running somewhere, but the difference to
normal approaches is that the organization building and supporting a ‘Serverless’
application is not looking after the hardware or the processes - they are
outsourcing this to a vendor." 

\hfill Mike Roberts

\hfill 2016

The most important area of serverless, for this paper, is
\textbf{Function-as-a-Service (FaaS)} in which, the server-side logic is still
written and controlled by the developers, but they run in stateless containers
that are triggered by events, ephemeral and are fully managed by the 3rd party
entity.

\subsection{Fog Computing}
Fog Computing is a virtual resource paradigm, located in between the Cloud
layer(traditional cloud or data centers) and the Edge layer (smart end devices) in
order to provide computing power, storage, and networking services. Although
conceptually located in between the two layers, in practice, this platform is located at the
edge of the network \cite{kn:Bonomi}. "This paradigm supports vertically-isolated,
latency-sensitive applications by providing ubiquitous, scalable, layered,
federated, and distributed computing, storage, and network connectivity"
\citep{kn:Iorga2017}. 

\section{State of the Art}

Talvez falar do problema de Exploration vs exploitation?

\section{Problem Statement}

As stated before in previous sections, not only is expected for the number of IoT
devices to grow imensely, both commercially and industrially, but there are
already many solutions that allow for serverless functions to be executed
remotely. Due to the nature of serverless functions, some of them could perfectly
be executed locally, using the joint processing power of the multiple IoT devices.
The hardship comes with using this power efficiently, having multiple serverless
functions, and knowing where to execute each one, locally or remotely. It is not
feasible for each developer to manually analyze performance across the different
runtime environments and make a decision where the function should be executed.
This is impending the adoption of these concepts in IoT, despite the interest and
potential that exists in this evergrowing area. Not only there is a lack of
systems making use of serverless on-premises, the majority of the developers in
IoT opt for using the cloud for each and every need, disregarding the power that
exists locally.

Like what was presented above, there is a lack of practical know-how knowledge
available despite there being lots of incentives for it. There are lots of things,
but it is not easy to start developing a serverless IoT solution.

Given this, the aim of this project is to create an architecture for serverless IoT
platform and to build a proof of concept using existing open-source tools when
possible and avoiding proprietary solutions. The platform should:
\begin{itemize}
    \item Have a serverless cloud solution capable of answering HTTP requests from
        the \textit{things}.
    \item Make use of the local processing power of the multiple IoT devices to
        create a serverless virtual processing unit on the Fog Layer to answer
        local requests.
    \item Have multiple IoT devices with different functions capable of
        interacting with both the Cloud and Fog layer to execute different
        functions. 
\end{itemize}

\section{Proposed Solution}

This project tries to fix the problem stated in Chapter \ref{chap:thesis_state} by
introducing a proxy between the entity requesting the function execution and the
serverless function. This proxy will analyze each function's past history, by
looking at the time taken in past requests and make the decision of which runtime
environment \footnote{Runtime environment is the system where the serverless
function will be executed, i.e., local network or one of the servers available in
the cloud} should the request be forwarded to, see Figure
\ref{fig:request_func_high_level_diagram}. The proxy should be able to decide
between the local network of devices and one of the many available servers.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{diss-high-level-diagram.png}
  \caption{High level overview of project's architechture}
  \label{fig:request_func_high_level_diagram}
\end{figure}

In order to improve fault-tolerance, in case of no Internet connection or if
one the servers is not available, if the request to the server fails, the proxy
should fallback to the local network. This way, even if the request to execute the
function is forwarded to the server and fails, the function will still be executed
locally.

The proxy is situated inside the local network of IoT devices and will forward the
request for a specific function to a gateway which forwards the function execution to
one of the IoT devices capable of executing the function. The load management,
containerization, replication, and clustering of the serverless functions is not
handled by the proxy, but it still has to be aware of the serverless functions
installed in the local network or any of the other runtime environments.

\subsection{Expected results and flow: Use cases}
\label{overview:usecases}
The following examples explain the expected results and decision-making of the
proposed solution. The decisions taken by the proxy are based only on previous
metrics of the time taken for the runtime environment to execute the function
(including network latency).

\subsubsection{Forward function execution to the cloud} \label{usecases:forward_cloud}

The use case in Figure \ref{fig:succ-cloud-deploy} examplifies a situation where
the requested serverless function is hardware intensive, therefore taking a lot of
time to execute locally. Due to the high processing power of the cloud servers, it
is beneficial to forward the execution request to one of the cloud servers, even
when considering the connection latency. From the multiple available servers, it
will opt for the one that is physically nearest (lower latency).

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{diss-succ-cloud-deploy.png}
    \caption{Request for the execution of a demanding function to be executed. The
    proxy will forward the request to the cloud because due to the high processing
    power of the cloud server, the function will be executed more quickly. The nearest
    server was choosen because of latency.}
    \label{fig:succ-cloud-deploy}
  \end{center}
\end{figure}

\subsubsection{Forward function execution to the local network}
\label{usecases:forward_local}

Contrary to the previous case, the Figure \ref{fig:succ-local-deploy} portays a
scenario where the requested serverless function is very light, being more
beneficial to execute the function locally and avoid network latency. Despite the
difference in power between the two environments, the previous metrics show that
the local environment is capable of satisfying the request more quickly.

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{diss-succ-local-deploy.png}
    \caption{Request for the execution of a simple, light function to be executed. The
    proxy will forward the request to be run locally, as there is no benefit in
    executing the function on the cloud.}
    \label{fig:succ-local-deploy}
  \end{center}
\end{figure}

\subsubsection{Fallback to the local network}
\label{usecases:fallback}

The Figure \ref{fig:fallback-local} depicts a scenario where the proxy first tries
to forward the request to one of the cloud servers (because it is more beneficial)
but fails in doing so. The proxy then decides to forward the request to the local
network, successfully completing the request. There are certain situations where
it is more favorable for the function to be executed on the cloud but it could
still be executed locally. Because it is not possible to always guarantee a
working connection, in these cases, if the connection fails the proxy will
fallback to execute function locally, assuring fail redundancy and the reliability
of the system.

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{diss-fallback-local.png}
    \caption{The request for the function execution to be in the cloud could not
    be satified (e.g., no internet connection). The proxy will then forward the
request for it to be executed in the local network.}
    \label{fig:fallback-local}
  \end{center}
\end{figure}

\subsubsection{Manual forward. Bypass the weighting process}
\label{usecases:manual_forward}

It should also be possible for the developer to bypass the weighting process (the
evaluation of the different runtime environments) and manually choose where to forward the
request. This option should be possible either in the setup process of the
function or as an argument of the request for the function execution. 

%\subsubsection*{Overall sequence} 
%In a very summarized way, the proxy when receiving a request will first decide, from
%a list of various runtime environments (the list must include the local network of
%devices and one or more cloud servers), where to forward the request to execute a
%serverless function. It will decide based on previous metrics of the time taken
%for the function to execute in the different runtime environments, and will aim to
%choose the one with less time taken. It is also possible for the runtime
%environment to be manually configured in the request options or when setting up
%the proxy. If it decides to forward the request to the local network, it will
%just wait for it to execute. If it decides to execute the function in one of the
%cloud servers, it will make a request to the cloud server for it to execute the
%serverless function and if this request fails (e.g. because there is no connection to
%the server), it will then try to execute the function in the local network of
%devices. After having the response from the function execution, the proxy will
%answer with the response. A sequence diagram of this process summarized can be
%seen in \ref{fig:high_level_request_func_seq_diagram}.

%\begin{figure}[ht]
  %\begin{center}
    %\includegraphics[width=0.5\textwidth]{diss-high-level-sequence-diagram.png}
    %\caption{High level sequence the whole process. This diagram sums the
        %decision-making of the project when trying to answer the request for the
        %function execution}
        %\label{fig:high_level_request_func_seq_diagram}
  %\end{center}
%\end{figure}

\subsection{Weighting the runtime environments}

In order to make the decision of which runtime environment to forward the function
to, there has to be some weighting process that will weight each of the runtime
environments and compare them. This process will gather information about the
different runtime environments and then make an accurate estimation of which one
is the best choice (less time taken). This is similar to the Exploration vs
Exploitation problem presented in \ref{sec:sota_mab}. Therefore, the following
algorithms were implemented to handle the weighting process:

\begin{itemize}
    \item \textbf{Greedy} - Has no exploration, simply assigns the weight as the
        mean average time taken.
    \item \textbf{UCB1} - Uses Hoeffding's Inequality to balance between
        exploration and exploitation, but the cumulative regret will still be
        considerable.
    \item \textbf{Bayesian UCB} - Analyzes the reward distribution to make a very
        accurate prediction of the weight but requires previous knowledge about the
        environments.
\end{itemize}

The developer or device can choose which of the weighting algorithms will be used
for that request, in the options, but the default algorithm is UCB1. UCB1 was
selected as default because despite Bayesian UCB being better, it requires
previous knowledge about the environment, as stated in \ref{sota:bayesian_ucb}.

\subsection{Code components}

As it can be seen in Figure \ref{fig:component_diagram}, the proposed solution is
constituted of two main components, the \textbf{proxy} and the
\textbf{sample\_functions}. Each of these components is a package in itself.

\subsubsection{Packages}

\begin{itemize}
    \item \textbf{proxy} - The main package of the project responsible for
        all the logic. Deals with the reception of the request for the execution
        of a function, with the weighting of the environments in which the
        functions can run (locally or in the cloud in one of the multiple
        servers), and with the storage and retrieval of all metrics of previous
        function executions. 
    \item \textbf{sample\_functions} - The package that contains the serverless functions
        whose execution is going to be requested to the proxy package. This
        package is purelly a sample with the purpose of simulating and analyzing
        resource demanding serverless functions (either light or heavy) and could be replaced
        by any other set of functions. The functions inside this package can be
        executed on either the local environment or on one of the servers (remote
        environments).
\end{itemize}

\subsubsection*{proxy}


All the different functions inside the proxy package communicate through HTTP and
expect to receive the content as application/json.

\begin{itemize}
    \item \textbf{proxy} - The main function through which all requests go through
        first. After receiving the list of weights associated to the execution of
        the requested function in each environment, it will choose the environment
        with the least weight and forward the execution of the serverless function
        to that runtime environment.
    \item \textbf{weight\_scale} - This function will analyze all the collected 
        metrics of the requested function and assign a weight to each runtime
        environment. It allows more than one algorithm for weight estimation.
    \item \textbf{get\_duration} - Retrieves the list of all the collected
        metrics of a function.
    \item \textbf{insert\_duration} - Store the time taken for a function to
        execute.
    \item \textbf{get\_overall\_stats} - Function that will return the summarized
        records of all the collected metrics for each function in each
        environment. Useful for analysis and evaluation of the results.
\end{itemize}

\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{diss-component-diagram}
    \caption{Component diagram of the project}
    \label{fig:component_diagram}
  \end{center}
\end{figure}

\subsubsection*{sample\_functions} \label{overview:sample_functions}

The serverless functions in this package have the purpose of simulating real serverless
functions with different purposes and execution times. The functions are aware of
the runtime environment they are being executed on and it is possible for them the answer
differently according to this. Here, the different time taken is simulated using a
\textit{wait} and using different values for different runtime environments.
 

\begin{itemize}
    \item \textbf{func\_light} - This function answers instantly, there should be
        no difference between executing the function locally or in the cloud,
        other than connection latency.
    \item \textbf{func\_heavy} - In this function there is a \textit{wait} of 2 seconds if
        it is executed locally or a \textit{wait} of 1 second
        if it is executed on the cloud. There should be no difference in the time
        taken across different cloud servers other than connection latency.
    \item \textbf{func\_super\_heavy} - similar to \textit{func\_heavy} but here the
        difference in time is bigger. There is a \textit{wait} of 4 seconds if the
        function is executed locally or a \textit{wait} of 2 seconds if the
        function is executed in the cloud.
    \item \textbf{func\_obese\_heavy} - This is a function that, due to its nature, it can
        only be executed in the cloud and its execution has been flagged as
        cloud-only. The proxy will not even try to run the function locally, it
        will always forward the request to the cloud. Because of this, there is no
        fallback to run locally.
\end{itemize}



\section{Experimentation and evaluation}

\subsection{First Experiment: With internet connection}
For this experiment both cloud servers were up and running and it were perfomed
99 iterations of requests. In each iteration was requested for every single one
of the serverless functions in \textit{sample\_functions} (see
\ref{overview:sample_functions} and \ref{impl:sample_functions}) to be executed.
The system has no knowledge about the environment. The aim here is to identify
that it is accomplishing the mentioned use cases \ref{usecases:forward_cloud},
\ref{usecases:forward_local}, and \ref{usecases:manual_forward}


It is expected that the proxy will forward requests for \textit{func\_light} to be
executed locally, for \textit{func\_heavy} requests to be executed either locally
or in the cloud. It will depende on the impact of the connection latency, but
generally, the connection latency should be less than 1 second (difference in time
that takes for the function to execute locally and remotely), which means that the
expected result is for proxy to choose to forward to one of the cloud servers.
\textit{func\_super\_heavy} is expected to be executed in the cloud most of the
times, due to the big difference in time taken, and the function
\textit{func\_obese\_heavy} should always be executed in the London server because
it is configured that way. Apart from \textit{func\_obese\_heavy}, some
exploration is expected for each of the different environments and not only
exploitation of the runtime environment that the system considers as the best
option. Because of the latency verified in \ref{res:conn_latency}, when choosing
between one of the servers, it should choose the Frankfurt server, because it is
the one with less latency (despite being physically further).

\subsubsection{Results}

%\begin{table}[]
%\centering
%\caption{Results of 1st experiment.}
%\label{tab:first_exp_results}
%\footnotesize
%\begin{tabular}{cl|c|c|c|c|}
%\cline{3-6}
%\multicolumn{1}{l}{}                                               &               & \multicolumn{1}{l|}{\textbf{func\_light}} & \multicolumn{1}{l|}{\textbf{func\_heavy}} & \multicolumn{1}{l|}{\textbf{func\_super\_heavy}} & \multicolumn{1}{l|}{\textbf{func\_obese\_heavy}} \\ \hline
%\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{local}}}              & avg. time (s) & 0.085602                                  & 2.111840                                  & 4.100240                                         & -                                                \\ \cline{2-6} 
%\multicolumn{1}{|c|}{}                                             & count         & 94                                        & 20                                        & 25                                               & -                                                \\ \hline
%\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{London's server}}}    & avg. time (s) & 3.423012                                  & 5.741277                                  & 6.169448                                         & 3.384546                                         \\ \cline{2-6} 
%\multicolumn{1}{|c|}{}                                             & count         & 3                                         & 10                                        & 20                                               & 99                                               \\ \hline
%\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Frankfurt's server}}} & avg. time (s) & 0.336398                                  & 1.253591                                  & 2.265615                                         & -                                                \\ \cline{2-6} 
%\multicolumn{1}{|c|}{}                                             & count         & 2                                         & 69                                        & 54                                               & -                                                \\ \hline
%\end{tabular}
%\end{table}

The obtained results, see Table \ref{tab:first_exp_results}, match the expected
results. For \textit{func\_light}, the time taken was so small (less than 1/10 of
a second) that proxy imediatly converged in the best option. The results for the
execution of the function \textit{func\_light} translate the results expected for
use case \ref{usecases:forward_local}.

For \textit{func\_heavy} and \textit{func\_super\_heavy}, it kept a ratio of
exploration vs exploitation of 3/7 and 5/6, respectively, but always choosing the
fastest of the cloud servers. The exploration rate also increases with the
duration of the execution, meaning that the proxy will look for better options the
longer it takes for a function to execute. The results for these two functions
correspond to the ones expected in use case \ref{usecases:forward_cloud}.

Also, as expected, \textit{func\_obese\_heavy} had a 100\% accuracy, thus matching
the expected outcome stated in use case \ref{usecases:manual_forward}.

\subsection{Second Experiment: Without internet connection to the servers}
For this experiment both servers were turned off and the internet connection was
cut, leaving the system only operational locally. The system still keeps all the
knowledge acquired in the previous experiment.
The aim here is to identify that it is accomplishing the use case
\ref{usecases:fallback}.

In this experiment, it is expected for the weighting algorithm to suggest
executing the serverless function in one of the cloud servers, because it will
lead to a faster execution. Because there is no internet connection, it is
expected for the proxy to try to execute the function remotely, fail, and then to
fallback to the local runtime environment. In the end, the function should be
executed in the local runtime environment leading to the request being answered
successfully.

\subsubsection{Results}
First the function \textit{weight\_scale} is queried to know which of the runtime
environments the proxy is going to choose (because the proxy chooses the runtime
environment with less weight, knowing the weights allow us to know which option
the proxy is going to take). Because there is more information about the system,
the weight algorithm used was the Bayesian UCB. As it can be seen in the Listing
\ref{listing:exp_weight_query}, the runtime environment that is going to be
choosen is the Frankfurt's server.

\begin{listing}
\begin{lstlisting}[language=json, basicstyle=\footnotesize]
{
    "status": "success",
    "londonServer": 3.5747403999957266,
    "frankfurtServer": 1.1756422708191938,
    "local": 2.090245031544607
}

\end{lstlisting}
\caption{}
\label{listing:exp_weight_query}
\end{listing}

Even though the choosen runtime environment was Frankfurt's server, because there
was no internet connection it had to fallback to execute the function locally in
order to complete the request successfully, as seen in Listing
\ref{listing:exp_fallback_result}. The observed results match the ones expected
and also the proxy proceeded as stated in use case \ref{usecases:fallback}.

\begin{listing}
\begin{lstlisting}[language=json, basicstyle=\footnotesize]
{
    "nodeInfo": "61e20a65b48e ",
    "swarm": "local",
    "message": "I was able to achieve this result using
    HEAVY calculations",
    "status": "The light is ON"
}
\end{lstlisting}
\caption{The request was executed locally, as indicated by the key \textit{swarm},
which is the swarm (runtime environment) where the function was executed.
\textit{local}, is the name given to the local network of devices, as configured
when setting up the proxy.}
\label{listing:exp_fallback_result}
\end{listing}


\subsection{Third Experiment: Turning off Internet connection in a series of requests}
During this experiment, the main purpose is to run a cycle of requests and then
turn off the Internet access in the middle of the cycle to observe how this will
affect response times. It will be run 99 iterations of requests and in each
iteration it will be requested the execution of \textit{func\_heavy}, After
request number \textit{50}, the Internet connection will be cut off, leaving the
system only operational locally. The system will keep all the knowledge gathered
in the previous experiments. The aim here is to identify that it is accomplishing
the use case \ref{usecases:fallback} and how results vary throughout.

In this experiment, it is expected for the weighting algorithm to suggest
executing the serverless function in one of the cloud servers, because it will
lead to a faster execution. Because of this, the mean total time of the request should
be smaller in the first 50 requests. After the 50th request, because the internet
connection was cut off, the proxy will try to execute the function remotely, fail,
then fallback to execute the function locally, resulting in a larger mean total
time. 

\subsubsection{Results}

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{exp3_chart.png}
    \caption{Chart illustrating the results of the third experience.}
    \label{fig:exp3_chart}
  \end{center}
\end{figure}

The obtained results, illustrated in Figure \ref{fig:exp3_chart}, match the
expected results. The mean total time of the request when there was Internet
connection was \textbf{1,71466602} seconds, and, at iteration number 50, it
jumped to \textbf{4,253785939} seconds when the Internet connection was cut off.
Despite having no internet connection, the system was still able to complete the
request, just with an added delay. The added delay was due to the fact that it had
to try to execute the function remotely and also because of the increased time it
takes to execute the function locally (2 seconds). The complete list of results
gathered from this experiment can be found in \ref{ap1:3rd_exp_complete_results}.

\subsection{Fourth Experiment: Adapting to lag}
\label{res:exp4}
In this experiment, it is going to be executed a series of requests and after
reaching to a while, the Internet connection is going to be purposedly slowed to
see how the system reacts in situations of lag and slow connection. It will be run
249 iterations of requests and in each iteration it will be requested the
execution of \textit{func\_heavy}, After request number \textit{50}, the Internet
connection will be slowed down (\textbf{28 kbps UP, 14 kbps DOWN}) and the system
will continue to be asked to execute the functions. The system will have none of
the knowledge gathered in the previous experiments. The aim here is to identify
that it is accomplishing the use cases \ref{usecases:forward_cloud} and
\ref{usecases:forward_local}, and also that it is capable of adapting to changes
in the network.

In this experiment, it is expected that the system goes through three phases. In
the first phase, in the first 50 iterations, while the connection to the server is
working as expected, the system is supposed to gather information about the
environment and to converge to the best option (one of the cloud servers).

In the second phase, the Internet connection is slowed down and the execution of
function remotely should take longer than the execution of the function locally.
In this phase, the system is supposed to still converge to one of the cloud
servers but gradually diminishing the frequency in which it chooses the cloud
servers as the best option.

After this phase, the system will enter a third phase where the results gathered
after the introduction of network lag outweight the results gathered in the first
phase. Here, the system should start to converge to the local network as the
best option.


\subsubsection{Results}

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{exp4_total_time_chart.png}
    \caption{Requests total time throughout the various iterations of the
    fourth experiment }
    \label{fig:exp4_total_time_chart}
  \end{center}
\end{figure}


The gathered results can be observed in Figure \ref{fig:exp4_total_time_chart}. As
expected, the results for the first 50 iterations are the expected results in a
standard situation. After the introduction of network lag, we start to observe
spikes in the total time it takes for the function to be executed. This spikes
refer to the execution of the function remotely. In the first 30/40 requests after
the introduction of network lag (iterations 50 to 90), the frequency of requests
that are executed remotely is still high. The frequency starts to diminish
from that point on and at around iteration 175 the system starts to choose the
local network more frequently than the cloud servers.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{exp4_avg_chart.png}
    \caption{This figure ilustrates the cumulative average duration of
        the request throughout the various iterations of the fourth experiment.
        E.g., the value in iteration 50 (2.085604 seconds) is the average duration
        of the first 50 requests.}
    \label{fig:exp4_avg_chart}
  \end{center}
\end{figure}

Figure \ref{fig:exp4_avg_chart}, shows a different perpective of the results,
showing the cumulative average duration of the requests throughout the experiment.
It can be seen here that around iteration 175 the system changed course and
started to converge to the local network as the best option. This marks the point
where the system finally adapted to the changes introduced.

The various phases can be seen more easily here, in Figure
\ref{fig:exp4_avg_chart}. The first phase can be seen from iteration 0 to 50, the
second phase from iteration 50 to 175, and the third phase from iteration 175 to
250.

Nevertheless, it took around 125 iterations (from iteration 50 to iteration 175)
for the system to adapt. After 50 iterations where the system gathered information
that became invalid, it took the system 250\% more iterations to adapt to the new
conditions. These results show that the system, although capable of adapting, will
take a considerable amount of time to adapt to new conditions.


\section{Conclusion}
The experimentation and results presented in this paper go in accordance to
those expected and satisfy the proposed use cases in \ref{overview:usecases}. The
developed solution is capable of analyzing the knowledge it has over the ecosystem
and will make a decision that will lead to a faster execution time and at the
same time explore different options that might lead to better results.
Additionally, the developed solution is also capable of detecting failures in the
remote execution of the serverless function and solve that problem, executing the
function locally and answering the request successfully.

In sum, the proposed solution proved to be capable of answering the demanded use
cases and the used approach was fruitful. Nonetheless, there are limitations and
some questions that this approach cannot answer.
Despite the fact that the proposed solution already reaches a level that is very
beneficial for most of the practical applications, further development must be
made to reach a more compelling solution.

Within the fields surrounding this work, there is lot of uncharted
territory and unkown aspects. The choice between a serverless architecture and a
monolithic one is still not clear in all cases and adding these concepts and
infusing it with IoT and Fog Computing is a very new area. Because of this, the
principal contributions of this work were:

\begin{itemize}
    \item Inovative approach to the mix of IoT, fog computing and serverless. There
        is not much work in this mix of fields and this approach is both inovative
        and unseen.

    \item Enabling serverless both locally and remotely. The developer creating the
        serverless functions no longer has to actively choose where to deploy the
        functions to, it is possible to automate that process and still keep total
        regret at a minimum.

    \item The ability to run serverless functions locally even if the connection to
        the server fails and improvement of fault-tolerance in systems.

    \item Gathering of existing knowledge, tools, and platforms suitable for
        developing solutions in the areas of IoT, serverless and fog computing.

    \item Develpment of a functional prototype built on top of widelly used and
        mature solutions that can serve as inspiration for future and better
        solutions.
\end{itemize}

All the code and work made is openly available at \url{https://github.com/444Duarte/serverless-iot}

\subsection{Main Dificulties}
During development of this solution, some problems occurred that caused some distress and
troubled the overall solution.

\begin{itemize}
\item This fusion of different areas like IoT, fog computing and serverless is new
    and there is no clear path or approach. The uncertainty in what path to follow
    led to some mistakes and to a slower pace sometimes.

\item Not many, but some of the tools used to develop the functional prototype are
    also recent and poorly documented wich made it harder to build the functional
    prototype.

\item Adapting the exploration vs exploitation algorithms to our problem. The
    algorithms aim to maximize and the purpose was to minimize the cost

\item There were not enough resources to develop a proper local network of IoT
    devices and to create a trully authenthic ecosystem that would better simulate
    a real life environment.

\end{itemize}


\subsection{Future Work}
Despite the efforts made, there is still many improvements that could be made to
the developed work:

\begin{itemize}
    \item Stateful - Introducing statefulness and consistency across serverless
        different runtime environments is definetely a challenge but the end
        result would be of utmost usefulness and importance.
    \item Analyzis of other metrics other than time (e.g. energy consumption, CPU
        cycles, memory usage, network usage) - The time taken is not the only
        metric that is important when choosing where to execute a serverless
        function. Analyzing the impact of other metrics would also be appliable
        in other different contexts and is something to take into consideration.
        A solution mixing different points of view that analyzed different metrics
        to choose the overall best result is also a possibility that would be of
        great use.
    \item Static analysis to verify complexity of the function - A static analyzis
        of the function could largely improve the exploration vs exploitation
        problem, allowing the system to start with some knowledge about the
        complexity of the function, diminishing the total regret.
    \item Integrate metrics with Prometheus - This is a pratical quality of life
        improvement and only regards the technical implementation but would
        simplify the analyzis process.
    \item Replace the functional prototype with a viable real life solution that
        could augment serverless development - A viable real solution would
        certainly be appreciated would deeply impact the field and advance
        both research in these areas but also the development of real applications
        that took advantage of these concepts and technologies.
\end{itemize}







% conference papers do not normally have an appendix


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\end{thebibliography}




% that's all folks
\end{document}
